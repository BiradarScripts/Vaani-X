import os
import json
from dotenv import load_dotenv
import google.generativeai as genai
from google.ai.generativelanguage import Content, Part
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

# Load environment variables
load_dotenv()

# Retrieve API key from environment variable
API_KEY = os.getenv("GOOGLE_API_KEY")
if not API_KEY:
    raise Exception("API key not found. Please set the GOOGLE_API_KEY environment variable.")
else:
    genai.configure(api_key=API_KEY)  # Configure the API key

# Initialize the Google Gemini model
llm = genai.GenerativeModel("gemini-1.5-flash")  # Simplified initialization

# Define the prompt for generating question-answer pairs from a paragraph
dataset_creation_template = '''You are an assistant creating a JSON-format question-answer dataset from the following paragraph.
Analyze the paragraph and generate a set of question-answer pairs that each focus on a different main topic within the paragraph.

Output each pair in the following JSON structure:
{
  "instruction": "A question related to a key topic",
  "output": "A concise answer based on the paragraph"
}

Here is the paragraph:
{paragraph}

Please create question-answer pairs in this format.
'''

# Create a structured prompt using ChatPromptTemplate
prompt_for_dataset_creation = ChatPromptTemplate.from_messages(
    [
        ("system", dataset_creation_template),
        ("user", "{paragraph}")
    ]
)

# Initialize the output parser
parser_for_dataset_creation = StrOutputParser()

def create_qa_dataset_from_file(input_file="input.txt"):
    try:
        # Read the paragraph from input.txt
        with open(input_file, "r") as file:
            paragraph = file.read().strip()
        
        if not paragraph:
            print("Input file is empty.")
            return

        # Prepare the content parts with the paragraph
        content_parts = [
            Part(text=dataset_creation_template),  # System message with instructions
            Part(text=paragraph)  # Reference paragraph
        ]

        # Generate the content
        response = llm.generate_content(Content(parts=content_parts), stream=False)

        # Check if the response is empty
        if not response or not response.text:
            print("The response is empty. Please check the API configuration or input data.")
            return

        # Parse the AI's response into question-answer pairs
        parsed_response = parser_for_dataset_creation.invoke(response.text)

        # Process each question-answer pair and print the result
        qa_pairs = []
        lines = parsed_response.splitlines()
        for i in range(0, len(lines), 2):
            if lines[i].startswith("Q: ") and lines[i+1].startswith("A: "):
                question = lines[i][3:].strip()
                answer = lines[i+1][3:].strip()
                qa_pair = {
                    "instruction": question,
                    "output": answer
                }
                qa_pairs.append(qa_pair)

        # Print the question-answer pairs
        for pair in qa_pairs:
            print(json.dumps(pair, indent=4))

    except Exception as e:
        print(f"An error occurred: {e}")

# Call the function to generate a question-answer dataset and print the result
create_qa_dataset_from_file()
